## 1. Цель работы
Обучить модели:
* линейной регрессии
* логистической регрессии
Рассмотрено:
- Реализуем линейную и логистическую регрессию на PyTorch-тензорах с ручным вычислением градиентов (без autograd)
- Реализуем то же самое с помощью встроенных слоев и оптимизаторов PyTorch
- Познакомимся с концепцией цикла обучения (training loop)
- Научимся логировать метрики обучения
- Научимся сохранять веса и использовать state_dict
- Научимся работать с реальными датасетами из sklearn (diabetes, breast_cancer)
- Познакомимся с концепцией Dataset-классов для обёртки данных
- Научимся использовать DataLoader для обучения по батчам


## 2. Подготовка данных
| Датасет    | Записей | Признаков | Целевая колонка | Обработка NaN | Масштабирование | Категории |
|------------|---------|-----------|-----------------|---------------|-----------------|-----------|
| Spotify    | 232 725 | 23        | `popularity`    | median/0      | StandardScaler  | LabelEncoder |
| Titanic    | 891     | 11        | `Survived`      | median/"missing" | StandardScaler  | LabelEncoder |

Для ускорения экспериментов использовалась выборка `sample_frac`:
* Spotify — 10% (регрессия) (Большой датасет), чтобы обучение не занимало много времени,
* Titanic — 100 % (классификация).

## 3. Подбор гиперпараметров
Регрессия (Spotify) — поиск `optimizer ∈ {Adam}`, `lr ∈ {0.1, 0.01}`, `batch_size ∈ {16, 32}`.

Классификация (Titanic) — поиск `optimizer ∈ {SGD, Adam}`, тот же диапазон `lr`/`bs`.

Результаты сохранены в:  
`homework/plots/hyperparam_results.csv` и `hyperparam_results_cls.csv`.

| Задача | Лучший optimizer | lr  | batch_size | val_loss |
|--------|------------------|-----|------------|----------|
| Spotify | Adam | 0.01 | 32 | 0.56 |
| Titanic | Adam | 0.01 | 32 | 0.41 |


## 4. Сохранённые артефакты
* **Модели** — `homework/models/*.pt`  
* **Графики** — `homework/plots/*.png`  
* **Таблицы** — `homework/plots/*.csv`

---
**Вывод:** построен воспроизводимый pipeline с автоматической обработкой данных,
поиском гиперпараметров и базовым анализом признаков. Подбор гиперпараметрров и новых фич не везде дало положительный результат из-за особенностей датасетов и не линейных связей между признаками и таргетом.
Результат можно улучить, проведя анализ и выводя фичи аналитически. Для изучения следовало использовать более простоые датасеты с простыми связями.