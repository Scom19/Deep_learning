## 1. Цель работы
Обучить модели:
* линейной регрессии
* логистической регрессии
Рассмотреть:
- Реализуем линейную и логистическую регрессию на PyTorch-тензорах с ручным вычислением градиентов (без autograd)
- Реализуем то же самое с помощью встроенных слоев и оптимизаторов PyTorch
- Познакомимся с концепцией цикла обучения (training loop)
- Научимся логировать метрики обучения
- Научимся сохранять веса и использовать state_dict
- Научимся работать с реальными датасетами из sklearn (diabetes, breast_cancer)
- Познакомимся с концепцией Dataset-классов для обёртки данных
- Научимся использовать DataLoader для обучения по батчам

Изначально были выбраны 
## 2 Описание данных
| Датасет        | Объектов | Признаков | Цель        | NaN-политика        | Масштабирование | Категории |
|----------------|:-------:|:---------:|-------------|---------------------|-----------------|-----------|
| House Prices   | 1 460    | 79        | `SalePrice` | median → 0          | StandardScaler  | LabelEncoder |
| Heart Disease  | 303      | 13        | `target`    | median / "missing" | StandardScaler  | LabelEncoder |

Обе выборки использовались полностью (`sample_frac = 1.0`)

## 3 Подбор гиперпараметров
Общая решётка:
* `optimizer ∈ {SGD, Adam, RMSprop}`
* `learning rate ∈ {0.1, 0.01, 0.001}`
* `batch_size ∈ {16, 32, 64}`

Результаты сохраняются в:
* `homework/plots/hyperparam_results.csv` — регрессия
* `homework/plots/hyperparam_results_cls.csv` — классификация

| Задача          | Лучший optimiser | lr   | batch | val_loss |
|-----------------|------------------|------|-------|---------|
| House Prices    | Adam             | 0.01 | 32    | 0.122 |
| Heart Disease   | Adam             | 0.01 | 32    | 0.35 |

---


## 4 Обучение моделей
| Модель               | Эпох | Early Stopping | L1 / L2 λ | Val loss | F1  | ROC-AUC |
|----------------------|:---:|:--------------:|-----------|---------:|:---:|:-------:|
| Linear Regression    | 105 | ✓ (patience 10) | 1e-4 / 1e-4 | 0.122 | —  | — |
| Softmax Regression   | 72  | —              | —         | 0.35  | 0.84 | 0.90 |

Матрица ошибок сохранена как `heart_cm.png` (папка *homework/plots*).

---
## 5 Эксперимент с признаками
Для House Prices созданы полиномиальные признаки второй степени.

| Вариант   | Val MSE |
|-----------|--------:|
| Базовый   | 0.122 |
| Poly-2    | 0.105 |
-видим уменьшение ошибки
## 6 Сохранённые артефакты
* **Модели** — `homework/models/*.pt`
* **Графики** — `homework/plots/*.png`
* **Таблицы** — `homework/plots/*.csv`
* 
**Вывод:** В ходе выполнения задачи были выполнены все поставленные цели. Изначально были выбраны не очень показательные датасеты (Спотифай, титаник), в которых не было явных зависимостей между таргетом и признаками, из-за чего было сложно анализировать прирост на линейных моделях.
После изменения датасетов анализ логов, графиков, таблиц подтвердил улучшение метрик: ранняя остановка предотвращает переобучение, а гиперпараметры и подбор фичей помогают оптимизировать ошибки модели.